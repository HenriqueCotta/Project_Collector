Project_Collector
├── .git (ignored)
├── .venv (ignored)
├── .vscode (ignored)
├── Project_Collector.egg-info (ignored)
├── README.md (ignored)
├── configs
│   ├── >>> __init__.py <<<
│   ├── defaults
│   │   ├── >>> Amazilium-Foundation.json <<<
│   │   ├── >>> Project_Collector.json <<<
│   │   ├── >>> __init__.py <<<
│   │   └── >>> gepe-frontend.json <<<
│   ├── models
│   │   ├── >>> default_config.json <<<
│   │   └── >>> request_config.json <<<
│   └── requests
│       ├── >>> Amazilium-Foundation.json <<<
│       ├── >>> Project_Collector.json <<<
│       ├── >>> __init__.py <<<
│       └── >>> gepe-frontend.json <<<
├── context_scripts (ignored)
├── output_coleta.txt (ignored)
├── pj_output.txt (ignored)
├── requirements.txt (ignored)
├── setup.py (ignored)
└── src
    ├── >>> __init__.py <<<
    ├── __pycache__ (ignored)
    ├── >>> cli.py <<<
    ├── >>> collector.py <<<
    ├── >>> config.py <<<
    ├── >>> filter.py <<<
    ├── >>> main.py <<<
    ├── >>> parser.py <<<
    └── >>> tree.py <<<



--- configs\__init__.py:START ---

--- configs\__init__.py:END ---

--- configs\defaults\Amazilium-Foundation.json:START ---
{
    "DEFAULT_IGNORED_DIRS": {
        "GLOBS": [],
        "REGEX": [],
        "SUBSTRINGS": []
    },
    "DEFAULT_IGNORED_FILES": {
        "GLOBS": [],
        "REGEX": [],
        "SUBSTRINGS": []
    }
}
--- configs\defaults\Amazilium-Foundation.json:END ---

--- configs\defaults\gepe-frontend.json:START ---
{
    "DEFAULT_IGNORED_DIRS": {
        "GLOBS": [],
        "REGEX": [],
        "SUBSTRINGS": []
    },
    "DEFAULT_IGNORED_FILES": {
        "GLOBS": [],
        "REGEX": [],
        "SUBSTRINGS": []
    }
}
--- configs\defaults\gepe-frontend.json:END ---

--- configs\defaults\Project_Collector.json:START ---
{
    "DEFAULT_IGNORED_DIRS": {
        "GLOBS": [
            ".*",
            "*.egg-info"
        ],
        "REGEX": [],
        "SUBSTRINGS": [
            "context_scripts"
        ]
    },
    "DEFAULT_IGNORED_FILES": {
        "GLOBS": [],
        "REGEX": [],
        "SUBSTRINGS": [
            "output_coleta.txt",
            "pj_output.txt"
        ]
    }
}
--- configs\defaults\Project_Collector.json:END ---

--- configs\defaults\__init__.py:START ---

--- configs\defaults\__init__.py:END ---

--- configs\models\default_config.json:START ---
{
    "DEFAULT_IGNORED_DIRS": {
        "GLOBS": [],
        "REGEX": [],
        "SUBSTRINGS": []
    },
    "DEFAULT_IGNORED_FILES": {
        "GLOBS": [],
        "REGEX": [],
        "SUBSTRINGS": []
    }
}
--- configs\models\default_config.json:END ---

--- configs\models\request_config.json:START ---
{
    "ADDITIONAL_IGNORED_DIRS": {
        "GLOBS": [],
        "REGEX": [],
        "SUBSTRINGS": []
    },
    "ADDITIONAL_IGNORED_FILES": {
        "GLOBS": [],
        "REGEX": [],
        "SUBSTRINGS": []
    },
    "INCLUDE_FOLDER_PATTERNS": {
        "GLOBS": [],
        "REGEX": [],
        "SUBSTRINGS": []
    },
    "INCLUDE_FILE_PATTERNS": {
        "GLOBS": [],
        "REGEX": [],
        "SUBSTRINGS": []
    },
    "INCLUDE_CONTENT_PATTERNS": {
        "REGEX": [],
        "SUBSTRINGS": []
    }
}
--- configs\models\request_config.json:END ---

--- configs\requests\Amazilium-Foundation.json:START ---
{
    "ADDITIONAL_IGNORED_DIRS": {
        "GLOBS": [],
        "REGEX": [],
        "SUBSTRINGS": []
    },
    "ADDITIONAL_IGNORED_FILES": {
        "GLOBS": [],
        "REGEX": [],
        "SUBSTRINGS": []
    },
    "INCLUDE_FOLDER_PATTERNS": {
        "GLOBS": [],
        "REGEX": [],
        "SUBSTRINGS": []
    },
    "INCLUDE_FILE_PATTERNS": {
        "GLOBS": [],
        "REGEX": [],
        "SUBSTRINGS": []
    },
    "INCLUDE_CONTENT_PATTERNS": {
        "REGEX": [],
        "SUBSTRINGS": [
            "UsersRepository"
        ]
    }
}
--- configs\requests\Amazilium-Foundation.json:END ---

--- configs\requests\gepe-frontend.json:START ---
{
    "ADDITIONAL_IGNORED_DIRS": {
        "GLOBS": [],
        "REGEX": [],
        "SUBSTRINGS": []
    },
    "ADDITIONAL_IGNORED_FILES": {
        "GLOBS": [],
        "REGEX": [],
        "SUBSTRINGS": []
    },
    "INCLUDE_FOLDER_PATTERNS": {
        "GLOBS": [],
        "REGEX": [],
        "SUBSTRINGS": []
    },
    "INCLUDE_FILE_PATTERNS": {
        "GLOBS": [],
        "REGEX": [],
        "SUBSTRINGS": []
    },
    "INCLUDE_CONTENT_PATTERNS": {
        "REGEX": [],
        "SUBSTRINGS": []
    }
}
--- configs\requests\gepe-frontend.json:END ---

--- configs\requests\Project_Collector.json:START ---
{
    "ADDITIONAL_IGNORED_DIRS": {
        "GLOBS": [],
        "REGEX": [],
        "SUBSTRINGS": [
            "__pycache__"
        ]
    },
    "ADDITIONAL_IGNORED_FILES": {
        "GLOBS": [],
        "REGEX": [],
        "SUBSTRINGS": [
            "requirements.txt"
        ]
    },
    "INCLUDE_FOLDER_PATTERNS": {
        "GLOBS": [],
        "REGEX": [],
        "SUBSTRINGS": []
    },
    "INCLUDE_FILE_PATTERNS": {
        "GLOBS": [],
        "REGEX": [],
        "SUBSTRINGS": []
    },
    "INCLUDE_CONTENT_PATTERNS": {
        "REGEX": [],
        "SUBSTRINGS": []
    }
}
--- configs\requests\Project_Collector.json:END ---

--- configs\requests\__init__.py:START ---

--- configs\requests\__init__.py:END ---

--- src\cli.py:START ---
# project_collector/cli.py
from .parser import get_user_args
from .main import main

def run():
    main()

if __name__ == "__main__":
    run()

--- src\cli.py:END ---

--- src\collector.py:START ---
import os
from pathlib import Path
from typing import List, Tuple
from .filter import Filter
from .config import FilterConfig


def collect_file_content(
    directory: str,
    cfg: FilterConfig,
    only_tree: bool = False,
    verbose: bool = False
) -> Tuple[str, List[Path]]:
    """
    Percorre recursivamente `directory`, aplica filtros e:
      - Se only_tree=True: apenas determina quais arquivos ficam na árvore, sem coletar conteúdo.
      - Se only_tree=False: lê e concatena conteúdo dos arquivos incluídos.

    Args:
        directory: caminho da raiz a processar.
        cfg: FilterConfig já populado.
        only_tree: se True, ativa checagem de conteúdo para incluir na árvore.
        verbose: se True, imprime logs de inclusão/ignoração.

    Returns:
        content: string com blocos "--- path:START ---...---:END ---" para cada arquivo (vazio se only_tree=True).
        included: lista de Paths relativos (Path objects) dos arquivos incluídos.
    """
    root = Path(directory)
    flt = Filter(cfg)
    included: List[Path] = []
    content_blocks: List[str] = []
    
    # definimos quando checar conteúdo para includes
    content_check = only_tree or flt._has_content_inc

    for dirpath, dirnames, filenames in os.walk(root):
        current = Path(dirpath)
        # caminho relativo da pasta atual (string sem ".")
        rel = current.relative_to(root)
        rel_dir = rel.as_posix() if str(rel) != "." else ""

        # 1) Poda de subpastas
        pruned = []
        for d in dirnames:
            sub_rel = f"{rel_dir}/{d}" if rel_dir else d
            if not flt.is_excluded_dir(current / d, sub_rel):
                pruned.append(d)
        dirnames[:] = pruned

        # 2) Processa arquivos
        for fname in filenames:
            sub_rel = f"{rel_dir}/{fname}" if rel_dir else fname
            full_path = current / fname
            if flt.should_include(full_path, sub_rel):
                rel_path = Path(sub_rel)
                included.append(rel_path)
                if not only_tree:
                    if verbose:
                        print(f"Reading file: {full_path}")
                    try:
                        text = full_path.read_text(encoding='utf-8', errors='ignore')
                        block = (
                            f"\n--- {rel_path}:START ---\n"
                            + text
                            + f"\n--- {rel_path}:END ---\n"
                        )
                        content_blocks.append(block)
                    except Exception as e:
                        if verbose:
                            print(f"Error reading file {full_path}: {e}")
            elif verbose:
                print(f"Ignoring file: {full_path}")

    full_content = "".join(content_blocks)
    return full_content, included

--- src\collector.py:END ---

--- src\config.py:START ---
import json
import os
from pathlib import Path
import subprocess
import sys
from typing import Any, List, Optional
from .filter import PatternGroup, FilterConfig

# Base dos JSONs no pacote
_BASE = Path(__file__).parent.parent  / 'configs'
_DEFAULTS_DIR = _BASE / 'defaults'
_REQUESTS_DIR = _BASE / 'requests'
# Arquivo do default salvo pelo usuário
_DEFAULT_CONFIG_FILE = Path.home() / '.projcol_config'

def load_config(
    project: str,
    no_defaults: bool = False
) -> FilterConfig:
    """
    Carrega configurações para o perfil `project` a partir dos arquivos:
      - configs/defaults/<project>.json  (padrões de ignore)
      - configs/requests/<project>.json  (overrides e includes)

    Cada JSON deve ter seções aninhadas como:
      "DEFAULT_IGNORED_DIRS": {"GLOBS": [...], "REGEX": [...], "SUBSTRINGS": [...]}
      "DEFAULT_IGNORED_FILES": {...}
      "ADDITIONAL_IGNORED_DIRS": {...}
      "ADDITIONAL_IGNORED_FILES": {...}
      "INCLUDE_FOLDER_PATTERNS": {...}
      "INCLUDE_FILE_PATTERNS": {...}
      "INCLUDE_CONTENT_PATTERNS": {"REGEX": [...], "SUBSTRINGS": [...]}  # globs não usados

    Args:
        project: nome do perfil de configuração.
        no_defaults: se True, pula leitura de defaults.
    Returns:
        FilterConfig contendo todos os PatternGroup carregados.
    """
    # Paths dos diretórios de configuração
    base = Path(__file__).parent.parent / 'configs'
    def_file = base / 'defaults' / f'{project}.json'
    req_file = base / 'requests' / f'{project}.json'

    # Helper: parsing de PatternGroup
    def parse_group(obj: Any, allow_globs: bool = True) -> PatternGroup:
        if not isinstance(obj, dict):
            # se não for dict, assume vazio
            obj = {}
        globs      = obj.get('GLOBS', []) if allow_globs else []
        regex      = obj.get('REGEX', [])
        substrings = obj.get('SUBSTRINGS', [])
        return PatternGroup(globs=globs, regex=regex, substrings=substrings)

    # 1) Defaults
    if not no_defaults:
        if not def_file.exists():
            raise FileNotFoundError(f"Default config not found for project '{project}': {def_file}")
        try:
            raw_def = json.loads(def_file.read_text(encoding='utf-8'))
        except json.JSONDecodeError as e:
            raise ValueError(f"Invalid JSON in defaults file {def_file}: {e}")
    else:
        raw_def = {}

    default_dirs_group  = parse_group(raw_def.get('DEFAULT_IGNORED_DIRS', {}))
    default_files_group = parse_group(raw_def.get('DEFAULT_IGNORED_FILES', {}))

    # 2) Requests
    if not req_file.exists():
        raise FileNotFoundError(f"Request config not found for project '{project}': {req_file}")
    try:
        raw_req = json.loads(req_file.read_text(encoding='utf-8'))
    except json.JSONDecodeError as e:
        raise ValueError(f"Invalid JSON in request file {req_file}: {e}")

    additional_dirs_group  = parse_group(raw_req.get('ADDITIONAL_IGNORED_DIRS', {}))
    additional_files_group = parse_group(raw_req.get('ADDITIONAL_IGNORED_FILES', {}))
    include_folder_group   = parse_group(raw_req.get('INCLUDE_FOLDER_PATTERNS', {}))
    include_file_group     = parse_group(raw_req.get('INCLUDE_FILE_PATTERNS', {}))
    include_content_group  = parse_group(raw_req.get('INCLUDE_CONTENT_PATTERNS', {}), allow_globs=False)

    # 3) Monta e retorna FilterConfig
    return FilterConfig(
        default_ignored_dirs      = default_dirs_group,
        default_ignored_files     = default_files_group,
        additional_ignored_dirs   = additional_dirs_group,
        additional_ignored_files  = additional_files_group,
        include_folder            = include_folder_group,
        include_file              = include_file_group,
        include_content           = include_content_group,
    )
    
def read_default_config() -> str:
    if _DEFAULT_CONFIG_FILE.exists():
        return _DEFAULT_CONFIG_FILE.read_text(encoding='utf-8').strip()
    return "No default config set."


def write_default_config(name: str):
    _DEFAULT_CONFIG_FILE.write_text(name, encoding='utf-8')


def clear_default_config():
    if _DEFAULT_CONFIG_FILE.exists():
        _DEFAULT_CONFIG_FILE.unlink()


def list_configs() -> List[str]:
    """Retorna lista de todos os configs disponíveis (defaults ∪ requests)."""
    defs = {p.stem for p in _DEFAULTS_DIR.glob('*.json')}
    reqs = {p.stem for p in _REQUESTS_DIR.glob('*.json')}
    return sorted(defs.union(reqs))


def init_config(name: str):
    """Cria skeletons em defaults/ e requests/ para o config `name`."""
    skeleton_def = {
        "DEFAULT_IGNORED_DIRS":  {"GLOBS": [], "REGEX": [], "SUBSTRINGS": []},
        "DEFAULT_IGNORED_FILES": {"GLOBS": [], "REGEX": [], "SUBSTRINGS": []}
    }
    skeleton_req = {
        "ADDITIONAL_IGNORED_DIRS":  {"GLOBS": [], "REGEX": [], "SUBSTRINGS": []},
        "ADDITIONAL_IGNORED_FILES": {"GLOBS": [], "REGEX": [], "SUBSTRINGS": []},
        "INCLUDE_FOLDER_PATTERNS":  {"GLOBS": [], "REGEX": [], "SUBSTRINGS": []},
        "INCLUDE_FILE_PATTERNS":    {"GLOBS": [], "REGEX": [], "SUBSTRINGS": []},
        "INCLUDE_CONTENT_PATTERNS": {"REGEX": [], "SUBSTRINGS": []}
    }
    def_file = _DEFAULTS_DIR / f"{name}.json"
    req_file = _REQUESTS_DIR / f"{name}.json"

    if not def_file.exists():
        def_file.parent.mkdir(parents=True, exist_ok=True)
        def_file.write_text(json.dumps(skeleton_def, indent=4), encoding='utf-8')
    if not req_file.exists():
        req_file.parent.mkdir(parents=True, exist_ok=True)
        req_file.write_text(json.dumps(skeleton_req, indent=4), encoding='utf-8')


def choose_config(args) -> str:
    """Retorna o config a usar: override ou o default salvo; ou sai com erro."""
    if args.use_config:
        return args.use_config
    default = read_default_config()
    if default:
        return default
    print("Error: config not specified. Use --use-config or --set-config.", file=sys.stderr)
    sys.exit(1)


def open_config_in_editor(name: Optional[str] = None) -> None:
    """
    Abre no VSCode os arquivos defaults/<name>.json e requests/<name>.json.
    Se name for None ou vazio, usa o padrão salvo em _DEFAULT_CFG_FILE.
    Lança ValueError se algum não existir, ou FileNotFoundError se 'code' não estiver no PATH.
    """
    # determina o nome
    if not name:
        name = read_default_config()
    if not name:
        raise ValueError("Nenhum config padrão definido e nenhum CONFIG informado.")

    def_path = _DEFAULTS_DIR  / f"{name}.json"
    req_path = _REQUESTS_DIR  / f"{name}.json"

    faltantes = [p for p in (def_path, req_path) if not p.exists()]
    if faltantes:
        raise ValueError(f"Arquivos não encontrados: {', '.join(str(p) for p in faltantes)}")

    # chama o VSCode CLI
    try:
        subprocess.run(['code', str(def_path), str(req_path)], check=True)
    except FileNotFoundError:
        # fallback: abre com o app padrão de .json no Windows
        os.startfile(str(def_path))
        os.startfile(str(req_path))
        return
    except subprocess.CalledProcessError as e:
        raise RuntimeError(f"Falha ao abrir VSCode: {e}")
--- src\config.py:END ---

--- src\filter.py:START ---
import re
import fnmatch
from pathlib import Path
from dataclasses import dataclass
from typing import List, Pattern

@dataclass
class PatternGroup:
    globs: List[str]
    regex: List[str]
    substrings: List[str]

    @property
    def regex_patterns(self) -> List[Pattern]:
        return [re.compile(r) for r in self.regex]

@dataclass
class FilterConfig:
    default_ignored_dirs: PatternGroup
    default_ignored_files: PatternGroup
    additional_ignored_dirs: PatternGroup
    additional_ignored_files: PatternGroup
    include_folder: PatternGroup
    include_file: PatternGroup
    include_content: PatternGroup

class Filter:
    def __init__(self, cfg: FilterConfig):
        # Combina defaults + additional para exclusão\        
        self.exclude_dirs = PatternGroup(
            globs=cfg.default_ignored_dirs.globs + cfg.additional_ignored_dirs.globs,
            regex=cfg.default_ignored_dirs.regex + cfg.additional_ignored_dirs.regex,
            substrings=cfg.default_ignored_dirs.substrings + cfg.additional_ignored_dirs.substrings
        )
        self.exclude_files = PatternGroup(
            globs=cfg.default_ignored_files.globs + cfg.additional_ignored_files.globs,
            regex=cfg.default_ignored_files.regex + cfg.additional_ignored_files.regex,
            substrings=cfg.default_ignored_files.substrings + cfg.additional_ignored_files.substrings
        )
        # Includes
        self.include_folder = cfg.include_folder
        self.include_file = cfg.include_file
        self.include_content = PatternGroup(
            globs=[],
            regex=cfg.include_content.regex,
            substrings=cfg.include_content.substrings
        )
        # Flags
        self._has_folder_inc = bool(
            self.include_folder.globs
            or self.include_folder.regex
            or self.include_folder.substrings
        )
        self._has_file_inc = bool(
            self.include_file.globs
            or self.include_file.regex
            or self.include_file.substrings
        )
        self._has_content_inc = bool(
            self.include_content.regex
            or self.include_content.substrings
        )

    def _match(self, name: str, group: PatternGroup) -> bool:
        # Glob
        for pat in group.globs:
            if fnmatch.fnmatch(name, pat):
                return True
        # Regex
        for pat in group.regex_patterns:
            if pat.search(name):
                return True
        # Substrings
        for sub in group.substrings:
            if sub in name:
                return True
        return False

    def is_excluded_dir(self, path: Path, relpath: str) -> bool:
        """
        True se algum segmento de relpath OU o próprio relpath casar com exclude_dirs.
        """
        if relpath:
            segments = relpath.split('/')
            for seg in segments:
                if self._match(seg, self.exclude_dirs):
                    return True
            # multi-segment match
            if self._match(relpath, self.exclude_dirs):
                return True
        return False

    def is_excluded_file(self, filename: str) -> bool:
        return self._match(filename, self.exclude_files)

    def matches_include_folder(self, rel_dir: str, parent_segments: List[str]) -> bool:
        """
        True se não há include_folder ativo OU
        algum segmento casar OU rel_dir casar como multi-segmento.
        """
        if not self._has_folder_inc:
            return True
        for seg in parent_segments:
            if self._match(seg, self.include_folder):
                return True
        if self._match(rel_dir, self.include_folder):
            return True
        return False

    def matches_include_file(self, filename: str) -> bool:
        if not self._has_file_inc:
            return True
        return self._match(filename, self.include_file)

    def matches_include_content(self, path: Path) -> bool:
        if not self._has_content_inc:
            return True
        try:
            text = path.read_text(encoding='utf-8', errors='ignore')
        except Exception:
            return False
        for pat in self.include_content.regex_patterns:
            if pat.search(text):
                return True
        for sub in self.include_content.substrings:
            if sub in text:
                return True
        return False

    def should_include(self, path: Path, relpath: str) -> bool:
        # 1) Exclude dirs
        rel_dir = Path(relpath).parent.as_posix()
        if self.is_excluded_dir(path.parent, rel_dir):
            return False
        # 2) Exclude files
        if path.is_file() and self.is_excluded_file(path.name):
            return False
        # 3) Sem includes → inclui tudo não excluído
        if not (self._has_folder_inc or self._has_file_inc or self._has_content_inc):
            return True
        # 4) Include folder
        parent_segments = rel_dir.split('/') if rel_dir else []
        if not self.matches_include_folder(rel_dir, parent_segments):
            return False
        # 5) Include file
        if path.is_file() and not self.matches_include_file(path.name):
            return False
        # 6) Include content
        if path.is_file() and not self.matches_include_content(path):
            return False
        # 7) Passou em tudo
        return True
--- src\filter.py:END ---

--- src\main.py:START ---
import sys
from pathlib import Path

from .parser import get_user_args
from .config import (
    choose_config,
    load_config,
    open_config_in_editor,
    read_default_config,
    write_default_config,
    clear_default_config,
    list_configs,
    init_config,
)
from .collector import collect_file_content
from .tree import build_tree, print_tree


def resolve_directory(arg_dir: Path) -> Path:
    """Converte '.' ou caminho relativo/absoluto num Path expandido."""
    return (arg_dir if arg_dir.is_absolute() else Path.cwd() / arg_dir).expanduser()


def handle_config_commands(args) -> bool:
    """
    Trata os comandos de configuração (--list-configs, --init-config,
    --get-config, --clear-config, --set-config). Retorna True se
    executou alguma ação e deve sair ali mesmo.
    """
    if args.list_configs:
        current = read_default_config()
        print("Available configs:")
        for cfg in list_configs():
            mark = "*" if cfg == current else " "
            print(f"{mark} {cfg}")
        return True

    if args.init_config:
        init_config(args.init_config)
        return True

    if args.get_config:
        cur = read_default_config()
        print(cur or "No default config set.")
        return True
    
    if args.open_config is not None:
        try:
            open_config_in_editor(args.open_config or None)
        except Exception as e:
            print(f"Error: {e}", file=sys.stderr)
            sys.exit(1)
        return True


    if args.clear_config:
        clear_default_config()
        print("Default config cleared.")
        return True

    if args.set_config:
        write_default_config(args.set_config)
        print(f"Default config set to: {args.set_config}")
        return True

    return False

def run_collection(project_dir: Path, config_name: str, args):
    """Executa load_config → collect_file_content → build_tree → escreve pj_output.txt."""
    try:
        cfg = load_config(project=config_name, no_defaults=args.no_defaults)
    except Exception as e:
        print(f"Error loading config '{config_name}': {e}", file=sys.stderr)
        sys.exit(1)

    content, included = collect_file_content(
        directory=str(project_dir),
        cfg=cfg,
        only_tree=args.only_tree,
        verbose=args.verbose
    )

    tree = build_tree(project_dir, set(included))
    tree_str = project_dir.name + "\n" + print_tree(tree)

    out = Path('pj_output.txt')
    try:
        with out.open('w', encoding='utf-8', newline='\n') as f:
            f.write(tree_str)
            if not args.only_tree:
                f.write("\n\n")
                f.write(content)
    except Exception as e:
        print(f"Error writing output file: {e}", file=sys.stderr)
        sys.exit(1)

    print(f"Coleta completa. Saída salva em '{out}'")


def main():
    args = get_user_args()

    # 1) Gerenciamento de configs via funções de config.py
    if handle_config_commands(args):
        return

    # 2) Execução normal: precisa de directory
    if not args.directory:
        print("Error: directory not specified.", file=sys.stderr)
        sys.exit(1)

    project_dir = resolve_directory(args.directory)
    if not project_dir.is_dir():
        print(f"Error: '{project_dir}' is not a valid directory.", file=sys.stderr)
        sys.exit(1)

    # 3) Escolhe qual config usar e executa a coleta
    config_name = choose_config(args)
    run_collection(project_dir, config_name, args)


def run():
    main()


if __name__ == '__main__':
    run()

--- src\main.py:END ---

--- src\parser.py:START ---
import argparse
from pathlib import Path

def get_user_args():
    """
    Configura o CLI para:
        - Gerenciar config persistente (--config, --set-config, --clear-config, --show-config)
        - Processar diretório opcional (posicional)
        - Flags de execução (no_defaults, only_tree, verbose)

    Retorna:
        Namespace com atributos:
            directory: Path | None
            config: str | None
            set_config: str | None
            clear_config: bool
            show_config: bool
            no_defaults: bool
            only_tree: bool
            verbose: bool
    """
    parser = argparse.ArgumentParser(
        prog='hpc',
        description='Project Collector: coleta conteúdo e exibe árvore de diretórios'
    )
    # Diretório alvo: opcional para comandos de gerenciamento
    parser.add_argument(
        'directory',
        nargs='?',  # opcional
        type=lambda p: Path(p).expanduser(),
        help='Diretório raiz para processar (use "." para cwd ou caminho relativo)'
    )

    # Grupo para gerenciar config persistente
    group = parser.add_mutually_exclusive_group()
    # override temporário para esta execução
    group.add_argument(
        '--use-config', '-ucfg',
        dest='use_config',
        metavar='CONFIG',
        help='Config temporário para esta execução (sobrescreve o padrão)'
    )
    # define config padrão
    group.add_argument(
        '--set-config', '-scfg',
        dest='set_config',
        metavar='CONFIG',
        help='Define CONFIG como padrão para futuras execuções'
    )
    # limpa config padrão
    group.add_argument(
        '--clear-config', '-ccfg',
        action='store_true',
        dest='clear_config',
        help='Limpa o config padrão, voltando ao estado sem padrão'
    )
    # mostra config padrão
    group.add_argument(
        '--get-config', '-gcfg',
        action='store_true',
        dest='get_config',
        help='Mostra o config padrão atualmente definido'
    )
    group.add_argument(
        '--open-config', '-ocfg',
        nargs='?',
        const='',              # se passado sem valor
        metavar='CONFIG',
        dest='open_config',
        help=(
            'Abre no VSCode os JSONs de defaults e requests do CONFIG. '
            'Se sem CONFIG, abre o padrão salvo.'
        )
    )
    group.add_argument(
        '--init-config', '-icfg',
        metavar='CONFIG',
        dest='init_config',
        help='Cria (se não existirem) os arquivos defaults/CONFIG.json e requests/CONFIG.json'
    )
    group.add_argument(
        '--list-configs', '-lcfg',
        action='store_true',
        dest='list_configs',
        help='Lista todos os configs disponíveis'
    )

    # Flags de execução do collector
    parser.add_argument(
        '--no-defaults',
        action='store_true',
        help='Ignorar defaults ao carregar config'
    )
    parser.add_argument(
        '--only-tree',
        action='store_true',
        help='Gerar apenas árvore sem coletar conteúdo'
    )
    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='Modo verboso para debug'
    )

    return parser.parse_args()

--- src\parser.py:END ---

--- src\tree.py:START ---
from pathlib import Path
from typing import Dict, Any, Set


def build_tree(root: Path, included_set: Set[Path]) -> Dict[str, Any]:
    """
    Constrói um dicionário aninhado representando a árvore de diretórios,
    marcando arquivos e pastas ignorados.

    Args:
        root: Path absoluto para o diretório raiz.
        included_set: conjunto de Paths relativos ao root dos arquivos incluídos.

    Retorna:
        Um dict onde chaves são nomes de arquivos/pastas (com sufixos)
        e valores são sub-dicts (para pastas) ou None (para arquivos).
    """
    def _build(current_dir: Path) -> Dict[str, Any]:
        tree: Dict[str, Any] = {}
        # Ordena por nome para saída consistente
        for item in sorted(current_dir.iterdir(), key=lambda p: p.name):
            rel = item.relative_to(root)
            if item.is_dir():
                # Verifica se algum arquivo incluído vive abaixo desta pasta
                has_child = False
                for inc in included_set:
                    child_path = root / inc
                    try:
                        child_path.relative_to(item)
                        has_child = True
                        break
                    except ValueError:
                        continue
                if not has_child:
                    # Nenhum filho incluído: marca como ignorado e não expande
                    tree[f"{item.name} (ignored)"] = {}
                else:
                    # Há filhos incluídos: expande recursivamente
                    tree[item.name] = _build(item)
            else:
                # Arquivo: destaca se incluído, senão ignora
                if rel in included_set:
                    tree[f">>> {item.name} <<<"] = None
                else:
                    tree[f"{item.name} (ignored)"] = None
        return tree

    return _build(root)


def print_tree(tree: Dict[str, Any], prefix: str = "") -> str:
    """
    Gera uma representação em texto ASCII da árvore construída.

    Args:
        tree: dict gerado por build_tree
        prefix: prefixo de indentação para chamadas recursivas

    Retorna:
        Uma string com linhas contendo ├── e └── para conexões.
    """
    result = ""
    items = list(tree.items())
    for idx, (name, subtree) in enumerate(items):
        connector = "├── " if idx < len(items) - 1 else "└── "
        result += prefix + connector + name + "\n"
        if subtree:
            extension = "│   " if idx < len(items) - 1 else "    "
            result += print_tree(subtree, prefix + extension)
    return result

--- src\tree.py:END ---

--- src\__init__.py:START ---

--- src\__init__.py:END ---
